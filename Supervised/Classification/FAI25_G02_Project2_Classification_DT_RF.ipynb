{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Fundamentals of Artificial Intelligence**\n",
        "\n",
        "## MSc in Applied Artificial Intelligence 2025/2026 <br>\n",
        "## Group 02 - Project 2 - Decision Tree and Random Forest\n",
        "| Nome                              | Número de Aluno |\n",
        "|-----------------------------------|------------:|\n",
        "| Adelino Daniel da Rocha Vilaça    | a16939          |\n",
        "| António Jorge Magalhães da Rocha  | a26052          |"
      ],
      "metadata": {
        "id": "wqeU_rY-6n7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 0. - **INTRODUCTION**"
      ],
      "metadata": {
        "id": "0DP8dG9H68md"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy5dlTOoY-ys"
      },
      "source": [
        "## 0.1 - Goal\n",
        "> O objetivo principal deste projeto é desenvolver e avaliar modelos de *machine learning* (Árvore de Decisão e Random Forest) para a deteção de intrusões em cibersegurança. Pretende-se classificar sessões de rede como normais ou maliciosas (`attack_detected`) utilizando um dado *dataset*, e compreender as características-chave que contribuem para tais deteções.\n",
        "\n",
        "## 0.2 - Environment\n",
        "> O projeto é desenvolvido num ambiente Google Colaboratory, aproveitando os seus serviços de Jupyter Notebook baseados na *cloud*. A implementação utiliza a linguagem de programação Python e um conjunto de bibliotecas populares de ciência de dados e *machine learning*, incluindo `pandas` para manipulação de dados, `numpy` para operações numéricas, `matplotlib` e `seaborn` para visualização de dados, e `scikit-learn` para modelos de *machine learning* (Árvore de Decisão, Random Forest) e métricas de avaliação. A API do Kaggle é utilizada para descarregar o *dataset*.\n",
        "\n",
        "## 0.3 - Definitions\n",
        "-   **Árvore de Decisão (Decision Tree):** Um algoritmo de aprendizagem supervisionada não-paramétrico usado para tarefas de classificação e regressão. Constrói um modelo em forma de estrutura de árvore, onde os nós internos representam testes numa característica, os ramos representam o resultado do teste e os nós folha representam rótulos de classe ou valores.\n",
        "-   **Random Forest:** Um método de aprendizagem por *ensemble* para classificação, regressão e outras tarefas que opera construindo uma infinidade de árvores de decisão durante o treino e produzindo a classe que é o modo das classes (classificação) ou a previsão média (regressão) das árvores individuais. Ajuda a reduzir o *overfitting* e a melhorar a precisão.\n",
        "-   **Deteção de Intrusão em Cibersegurança:** O processo de monitorizar uma rede ou sistema informático para atividades maliciosas ou violações de políticas. Qualquer intrusão detetada é tipicamente reportada a um administrador ou recolhida centralmente usando um sistema de gestão de eventos e informações de segurança (SIEM).\n",
        "-   **Overfitting:** Um erro de modelagem que ocorre quando uma função se alinha demasiado a um conjunto limitado de pontos de dados. Significa que o modelo aprende os dados de treino e o seu ruído demasiado bem, levando a um desempenho fraco em dados não vistos.\n",
        "-   **`max_depth`:** Um hiperparâmetro em modelos baseados em árvores que especifica a profundidade máxima da árvore, da raiz à folha. Limitar a profundidade ajuda a prevenir o *overfitting*.\n",
        "-   **`LabelEncoder`:** Uma utilidade em `scikit-learn` usada para normalizar os rótulos de modo a que contenham apenas valores entre 0 e n_classes-1. É frequentemente usado para codificar características categóricas em formato numérico."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 1. - **AGENT DESIGN**"
      ],
      "metadata": {
        "id": "_aq6xgai7HeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 - Platforms"
      ],
      "metadata": {
        "id": "fc-pyw7E7LJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.1 - Jupyter Notebook <br>\n",
        " > A Jupyter Notebook is an open-source web application that allows creating and sharing documents containing live code, equations, visualizations, and narrative text. It's widely used in data science, machine learning, and scientific computing for interactive development, exploration, and documentation.\n",
        "\n",
        "### 1.1.2 - Google Colaboratory <br>\n",
        "  >Free cloud-based service that provides a hosted Jupyter Notebook environment. It allows writing and executing code in a browser for free and without any setup."
      ],
      "metadata": {
        "id": "sDN3jAn07NK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Packages and Libraries\n"
      ],
      "metadata": {
        "id": "UgUwo_RB7QNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2.1 Explicar \"libs\"\n",
        "- pandas (pd): Essencial para manipulação e análise de dados em formato de tabela (DataFrames).\n",
        "\n",
        "- numpy (np): A base para operações numéricas e matemáticas com arrays e matrizes.\n",
        "\n",
        "- matplotlib.pyplot (plt): Usada para criar gráficos e visualizações de dados estáticos.\n",
        "\n",
        "- seaborn (sns): Construída sobre o Matplotlib, serve para criar gráficos estatísticos mais complexos e esteticamente agradáveis.\n",
        "\n",
        "- sklearn.model_selection: Contém ferramentas para dividir dados (treino/teste) e realizar validação cruzada.\n",
        "\n",
        "- sklearn.tree: Oferece algoritmos para Árvores de Decisão e ferramentas para as visualizar.\n",
        "\n",
        "- sklearn.ensemble: Implementa métodos de conjunto como o Random Forest, que combina múltiplos modelos para melhor desempenho.\n",
        "\n",
        "- sklearn.metrics: Fornece métricas para avaliar o desempenho dos modelos, como precisão, recall, F1-score e matriz de confusão."
      ],
      "metadata": {
        "id": "4CP3QolQ7dik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "\n",
        "RANDOM_STATE = 27"
      ],
      "metadata": {
        "id": "FOc4cIwzTyWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "627fb0c4"
      },
      "source": [
        "### Uso do `kaggle.json`\n",
        "\n",
        "O ficheiro `kaggle.json` é um **token de autenticação** essencial para interagir com a API do Kaggle (Kaggle Application Programming Interface). Ele contém as credenciais de utilizador do Kaggle (username e key) de forma segura."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # kaggle.json"
      ],
      "metadata": {
        "id": "P7kytrCkpTCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Permissões para o Token"
      ],
      "metadata": {
        "id": "oO7LpjTxeorE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "dE4VHDzud0pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list | head"
      ],
      "metadata": {
        "id": "gVqBil5wd6wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 DATASET\n",
        "\n",
        "\n",
        "### 1.3.1 Explicação Dataset Usado\n",
        "\n",
        "> Este dataset, denominado `cybersecurity_intrusion_data.csv`, foca-se na **deteção de intrusões em cibersegurança**.\n",
        "\n",
        "*   Contém informações sobre sessões de rede, como tamanho dos pacotes, tipo de protocolo, duração da sessão e tentativas de login.\n",
        "*   Inclui detalhes sobre o comportamento do utilizador, como o tipo de navegador e tentativas falhadas de login.\n",
        "*   O objetivo principal é classificar se uma determinada sessão indica um `attack_detected` (ataque detetado) ou não, sendo esta a variável alvo.\n"
      ],
      "metadata": {
        "id": "FkMZuZYt7ZgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d dnkumars/cybersecurity-intrusion-detection-dataset -p /content/ --unzip"
      ],
      "metadata": {
        "id": "65QA6Q7LeJZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 2. **AGENT RUNNING**"
      ],
      "metadata": {
        "id": "W-ifaOIu7pxb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b7f402b"
      },
      "source": [
        "### 2.1 Leitura e Pré-visualização do Dataset\n",
        "\n",
        "Esta célula é responsável por carregar o dataset `cybersecurity_intrusion_data.csv` para um DataFrame do pandas e realizar uma inspeção inicial.\n",
        "\n",
        "* **`dataset = pd.read_csv('cybersecurity_intrusion_data.csv')`**: Carrega o ficheiro CSV para uma variável `dataset`.\n",
        "* **`df = dataset`**: Cria uma cópia do DataFrame `dataset` na variável `df` para facilitar a manipulação.\n",
        "* **`dataset_data = pd.DataFrame(dataset)`**: Cria outra cópia, `dataset_data`, que será utilizada para algumas visualizações ou transformações que preservam o `session_id`.\n",
        "* **`print(\"Shape:\", df.shape)`**: Exibe as dimensões do DataFrame (número de linhas e colunas).\n",
        "* **`dataset_data.head()`**: Mostra as primeiras 5 linhas do DataFrame, permitindo uma rápida visualização da estrutura e dos tipos de dados."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#0. Read the file\n",
        "dataset = pd.read_csv('cybersecurity_intrusion_data.csv')\n",
        "df = dataset\n",
        "dataset_data = pd.DataFrame(dataset)\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "dataset_data.head()\n"
      ],
      "metadata": {
        "id": "NgI17MbLTzxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Teste de Duplicados\n",
        "\n",
        "> Contagem de linhas/registos duplicados no dataset, podendo levar a uma limpeza prévia, para não prejudicar a análise realizada posteriormente!"
      ],
      "metadata": {
        "id": "R6GGaf1wmTn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.duplicated().sum()"
      ],
      "metadata": {
        "id": "7M2tkj8Lmiea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Lidar com Valores Omissos\n",
        "\n",
        "> Caso existam dados em falta, preencher os mesmos com `NaN` (Not a Number), atribuindo à variavel `data` para não influenciar o conteúdo original do `dataset` (como no caso `inplace=True`)"
      ],
      "metadata": {
        "id": "ZXfgdeYdWllM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=dataset.fillna(\"No Data\")"
      ],
      "metadata": {
        "id": "6abL4WnymTUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e607d698"
      },
      "source": [
        "### 2.4 Pairplot\n",
        "\n",
        "O Pairplot oferece uma visão multidimensional dos nossos dados, destacando as distribuições de cada **característica numérica** e as suas relações em pares, coloridas pela nossa variável alvo, `attack_detected`. Esta análise ajuda-nos a identificar padrões e potenciais preditores de ataques.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### 2.4.1 Análise Gráficos da Diagonal (Distribuição de Variáveis Numéricas Individuais)\n",
        "\n",
        "Os gráficos na diagonal (histogramas ou KDEs) mostram a distribuição de cada feature numérica, com as cores a diferenciar sessões sem ataque (azul, `attack_detected=0`) de sessões com ataque (laranja, `attack_detected=1`):\n",
        "\n",
        "*   **`network_packet_size`**: A distribuição dos tamanhos dos pacotes de rede parece bastante sobreposta para ambas as classes. Isto sugere que o tamanho do pacote por si só pode não ser um forte indicador isolado de ataque, embora padrões subtis possam existir.\n",
        "\n",
        "* **`login_attempts`**: A distribuição do número de tentativas de login para sessões de ataque (`attack_detected=1`) pode estar ligeiramente deslocada para valores mais altos, indicando que ataques podem envolver mais tentativas de login. Contudo, ainda pode haver uma sobreposição significativa com as sessões normais.\n",
        "\n",
        "* **`session_duration`**: As durações das sessões também podem mostrar distribuições sobrepostas. Picos ou caudas distintas para a classe de ataque poderiam indicar durações atípicas (muito curtas para ataques rápidos, ou muito longas para infiltrações lentas) associadas a certos tipos de intrusões.\n",
        "\n",
        "* **`ip_reputation_score`**: É provável que a distribuição para `attack_detected=1` (laranja) esteja mais concentrada em pontuações de reputação mais baixas, enquanto a distribuição para `attack_detected=0` (azul) tende a ter pontuações mais altas. IPs com má reputação são frequentemente usados em ataques.\n",
        "\n",
        "* **`failed_logins`**: A distribuição para sessões de ataque (`attack_detected=1`) espera-se que mostre uma frequência mais elevada de `failed_logins` ou uma extensão para valores mais altos. Tentativas de login falhadas são um sinal comum de atividades maliciosas.\n",
        "\n",
        "* **`unusual_time_access`**: Sendo binária (0 ou 1), a distribuição para `attack_detected=1` pode ter uma barra mais proeminente no valor `1`, sugerindo que ataques ocorrem mais frequentemente em horários incomuns.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### 2.4.2 Análise Gráficos Fora da Diagonal (Relação entre Pares de Variáveis Numéricas)\n",
        "\n",
        "Os gráficos de dispersão fora da diagonal revelam como dois pares de variáveis numéricas se relacionam, com a cor a indicar o estado do `attack_detected`:\n",
        "\n",
        "* **`failed_logins` vs. `ip_reputation_score`**: Este é um dos gráficos mais importantes. Devemos procurar por um **agrupamento claro dos pontos laranja (`attack_detected=1`) na área superior esquerda**, ou seja, com um número elevado de `failed_logins` e uma baixa `ip_reputation_score`. Se for evidente, esta combinação é um forte indicador de ataque.\n",
        "\n",
        "* **`unusual_time_access` vs. `failed_logins`**: Se `unusual_time_access` for 1 (acesso em horário incomum), e o número de `failed_logins` for alto, é provável que vejamos uma maior densidade de pontos laranja, sugerindo que estas condições combinadas são preditivas de ataques.\n",
        "\n",
        "* **`ip_reputation_score` vs. `session_duration` / `network_packet_size`**: Podemos investigar se sessões de IPs com má reputação (baixa `ip_reputation_score`) mostram padrões distintos na sua duração ou no tamanho dos pacotes (e.g., sessões muito curtas para scans rápidos, ou muito longas para infiltração lenta), especialmente para os pontos laranja.\n",
        "\n",
        "<br>\n",
        "\n",
        "### 2.4.3 Conclusão:\n",
        "\n",
        "A combinação de `failed_logins`, `ip_reputation_score`, e `unusual_time_access` parece ser promissora para diferenciar os ataques.\n",
        "\n",
        "<br>\n",
        "\n",
        "*(Nota: Variáveis categóricas como `protocol_type`, `encryption_used` e `browser_type` não são diretamente plotadas nos eixos do `pairplot` padrão, mas a sua influência é visível através da coloração (`hue`) quando a variável alvo é categórica. Para analisar essas variáveis individualmente ou em relação às numéricas, seriam necessários gráficos específicos para categorias, como countplots ou boxplots.)*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Pairplot\n",
        "sns.pairplot(dataset_data, hue='attack_detected')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "omdhl1wZXCLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cd533af"
      },
      "source": [
        "Após a visualização inicial com o Pairplot, removemos a coluna `session_id` do dataset pois é apenas um identificador e não uma feature útil para o modelo. Depois convertemos as colunas com tipo `'object'` para o tipo `'category'`, otimizando o uso de memória e preparando-as para codificação futura.\n",
        "<br>\n",
        "\n",
        "De seguida, usamos `dataset.dtypes` para verificação do tipo de cada parametro!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=dataset.drop([\"session_id\"],axis=1)"
      ],
      "metadata": {
        "id": "1W7F1InXis66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in dataset.select_dtypes(include='object').columns:\n",
        "    dataset[col] = dataset[col].astype('category')"
      ],
      "metadata": {
        "id": "eKjGh_J_isv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.dtypes"
      ],
      "metadata": {
        "id": "zKK783kKjYsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b56349c"
      },
      "source": [
        "Converte as colunas categóricas (não numéricas) para uma representação numérica. Utilizamos o `LabelEncoder` da Scikit-learn para atribuir um número inteiro único a cada categoria, tornando os dados compreensíveis para os algoritmos de modelagem."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "# encode all columns that are not of type integer or float (i.e., categorical columns)\n",
        "for col in dataset.select_dtypes(exclude=['int64', 'float64']).columns:\n",
        "    dataset[col] = label_encoder.fit_transform(dataset[col])"
      ],
      "metadata": {
        "id": "VNd17eE0iVxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f48e6577"
      },
      "source": [
        "O One-Hot Encoding resolve este problema criando novas colunas binárias (0 ou 1) para cada categoria única em uma variável. Por exemplo, se tivermos a variável `protocol_type` com categorias 'TCP', 'UDP' e 'ICMP', o One-Hot Encoding criaria três novas colunas: `protocol_type_TCP`, `protocol_type_UDP` e `protocol_type_ICMP`. Para uma observação 'TCP', a coluna `protocol_type_TCP` teria o valor 1 e as outras 0. Isso garante que o modelo não interprete qualquer relação ordinal entre as categorias, tratando-as como entidades independentes.\n",
        "\n",
        "Nesta implementação, utilizamos `pd.get_dummies()` que, por padrão, já lida com a remoção da primeira categoria (`drop_first=True`) para evitar a multicolinearidade, ou seja, a redundância de informação entre as novas colunas criadas."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding para todas as colunas categóricas\n",
        "dataset = pd.get_dummies(\n",
        "    dataset,\n",
        "    columns=dataset.select_dtypes(exclude=['int64','float64']).columns,\n",
        "    drop_first=True\n",
        ")"
      ],
      "metadata": {
        "id": "RHpvX8a-eYWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "983ba55a"
      },
      "source": [
        "### 2.5 Heatmap\n",
        "\n",
        "O heatmap (matriz de correlação) visualiza a relação linear entre todas as variáveis numéricas do conjunto de dados, incluindo aquelas que foram codificadas a partir de categorias (`protocol_type`, `encryption_used`, `browser_type`). Os valores variam de -1 a 1, onde:\n",
        "\n",
        "- **1** indica uma correlação positiva perfeita.\n",
        "- **-1** indica uma correlação negativa perfeita.\n",
        "- **0** indica nenhuma correlação linear.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Análise dos Resultados:\n",
        "\n",
        "1.  **`attack_detected` (Variável Alvo):**\n",
        "    *   **Correlações Positivas Fortes:** Observamos que `failed_logins` e `login_attempts` têm as correlações mais fortes e positivas com `attack_detected`. Isso sugere que um aumento no número de tentativas de login falhadas e nas tentativas de login está diretamente associado a uma maior probabilidade de deteção de ataque.\n",
        "    *   **Correlações Negativas Fortes:** A variável `ip_reputation_score` apresenta uma correlação negativa notável com `attack_detected`. Isso implica que IPs com menor reputação (valores mais baixos) estão fortemente associados a ataques, o que é um resultado esperado.\n",
        "    *   **Outras Correlações:** `unusual_time_access` também mostra uma correlação positiva, indicando que acessos fora do horário padrão contribuem para a deteção de ataques. `network_packet_size` e `session_duration` parecem ter correlações mais fracas, sugerindo que, isoladamente, podem não ser os preditores mais fortes.\n",
        "\n",
        "2.  **Correlações entre Features (Multicolinearidade):**\n",
        "    *   É importante observar também as correlações entre as próprias features. Correlações muito altas entre duas features preditoras podem indicar multicolinearidade, o que pode afetar a estabilidade de alguns modelos, mas geralmente não é um problema para modelos baseados em árvores como as Árvores de Decisão e Random Forests.\n",
        "\n",
        "#### Nota:\n",
        "\n",
        "O heatmap confirma que `failed_logins`, `ip_reputation_score`, `login_attempts` e `unusual_time_access` são as variáveis mais influentes na previsão de `attack_detected`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the correlation Matrix\n",
        "sns.heatmap(dataset.corr(), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dHTWKbO2ju_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fad9077"
      },
      "source": [
        "### 2.5.1 Boxplot\n",
        "\n",
        "Os boxplots mostram a distribuição de cada variável numérica (`network_packet_size`, `login_attempts`, `session_duration`, `ip_reputation_score`, `failed_logins`) em relação à variável alvo `attack_detected` (0 para não detetado, 1 para detetado). Esta visualização é excelente para identificar diferenças nas medianas, dispersão e presença de *outliers* entre as duas classes.\n",
        "\n",
        "#### Interpretação dos Boxplots:\n",
        "\n",
        "*   **`network_packet_size`**: Se a mediana e a dispersão dos tamanhos de pacotes forem semelhantes para ambas as classes (0 e 1), esta variável pode não ser um forte preditor isolado de ataques. No entanto, se houver uma ligeira diferença ou *outliers* notáveis numa das classes, isso pode indicar padrões subtis.\n",
        "\n",
        "*   **`login_attempts`**: Espera-se que as sessões com `attack_detected=1` apresentem uma mediana e/ou uma dispersão de `login_attempts` maior. Isto porque os ataques, como tentativas de força bruta, geralmente envolvem um número elevado de tentativas de login.\n",
        "\n",
        "*   **`session_duration`**: A duração da sessão pode ser um indicador complexo. Ataques rápidos podem ter durações curtas, enquanto ataques de persistência podem ter durações longas. Observaremos se as distribuições para `attack_detected=1` mostram uma concentração em durações muito curtas ou muito longas, ou se são significativamente diferentes da classe `attack_detected=0`.\n",
        "\n",
        "*   **`ip_reputation_score`**: Esta é uma variável crucial. É altamente provável que o boxplot para `attack_detected=1` esteja deslocado para valores mais baixos de `ip_reputation_score`, indicando que IPs com má reputação estão mais associados a ataques. A dispersão também pode ser menor, sugerindo que ataques tendem a vir de IPs com pontuações consistentemente baixas.\n",
        "\n",
        "*   **`failed_logins`**: Semelhante a `login_attempts`, espera-se que as sessões com `attack_detected=1` mostrem um número significativamente maior de `failed_logins`. Uma mediana mais alta e/ou uma maior dispersão para esta classe seria um forte indício de atividade maliciosa.\n",
        "\n",
        "#### Nota:\n",
        "\n",
        "Variáveis com distribuições claramente separadas entre as duas classes (como provavelmente `failed_logins` e `ip_reputation_score`) serão os preditores mais fortes para os modelos."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplots para variáveis numéricas face a 'attack_detected'\n",
        "\n",
        "# Colunas numéricas adequadas para boxplots\n",
        "numerical_cols = [\n",
        "    'network_packet_size',\n",
        "    'login_attempts',\n",
        "    'session_duration',\n",
        "    'ip_reputation_score',\n",
        "    'failed_logins'\n",
        "]\n",
        "\n",
        "# Layout para os subplots\n",
        "plt.figure(figsize=(18, 12)) # Tamanho geral da figura\n",
        "\n",
        "for i, col in enumerate(numerical_cols):\n",
        "    plt.subplot(2, 3, i + 1) # 2 linhas e 3 colunas\n",
        "    sns.boxplot(x='attack_detected', y=col, data=dataset)\n",
        "    plt.title(f'Distribuição de {col} por Ataque Detetado', fontsize=12)\n",
        "    plt.xlabel('Ataque Detetado (0=Não, 1=Sim)', fontsize=10)\n",
        "    plt.ylabel(col, fontsize=10)\n",
        "    plt.xticks(fontsize=9)\n",
        "    plt.yticks(fontsize=9)\n",
        "\n",
        "plt.tight_layout() # Auto adjust -> parâmetros do subplot para que caibam na área da figura\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8lrwuLKsYHpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eb67a2b"
      },
      "source": [
        "### 2.5.2 Histograma de Tamanho de Pacotes de Rede por Deteção de Ataque\n",
        "\n",
        "Este histograma visualiza a distribuição do `network_packet_size` (tamanho dos pacotes de rede) para sessões com e sem ataque, utilizando a variável `attack_detected` para diferenciação. Permite-nos observar a frequência de diferentes tamanhos de pacotes em ambas as classes.\n",
        "\n",
        "#### Interpretação:\n",
        "\n",
        "*   Ao analisar a sobreposição ou separação das distribuições para `attack_detected=0` (sem ataque) e `attack_detected=1` (com ataque), podemos verificar se o tamanho dos pacotes de rede é um indicador forte ou fraco de um ataque.\n",
        "*   Se as distribuições forem muito semelhantes, o `network_packet_size` pode não ser, por si só, um preditor distintivo. No entanto, diferenças subtis em picos ou dispersão podem ainda oferecer alguma informação útil para o modelo.\n",
        "\n",
        "Este gráfico complementa a análise dos boxplots, fornecendo uma visão mais detalhada da frequência de cada valor ou intervalo de valores do tamanho dos pacotes de rede."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Histogram of Network Packet Size by Attack Detected\n",
        "for category in dataset_data['attack_detected'].unique():\n",
        "\tsubset = dataset_data[dataset_data['attack_detected'] == category]\n",
        "\tsns.histplot(subset['network_packet_size'], label=f'Attack: {category}', kde=False)\n",
        "\n",
        "plt.xlabel('Network Packet Size')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Network Packet Size by Attack Detected')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X-sd3zliZKwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.6 Hold-Out"
      ],
      "metadata": {
        "id": "XbzAiDXOpFc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.6.1 Model building"
      ],
      "metadata": {
        "id": "OWdbGjsOa4X-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = dataset.drop(columns=['attack_detected'],axis=1)\n",
        "y = dataset['attack_detected']\n",
        "\n",
        "#Split the data\n",
        "X_train , X_test , y_train , y_test = train_test_split(x,y,test_size=0.3,random_state=42,stratify=y)"
      ],
      "metadata": {
        "id": "27sIuJrWyJKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27beb66e"
      },
      "source": [
        "### 2.6.2 Decision tree - Model building\n",
        "\n",
        "Nesta secção, vamos construir o nosso primeiro modelo de Árvore de Decisão e tentar visualizá-lo para entender as regras que ele aprendeu.\n",
        "\n",
        "<br>\n",
        "\n",
        "1.  **Instanciação do Modelo de Árvore de Decisão**:\n",
        "    *   **`dt = DecisionTreeClassifier(random_state=RANDOM_STATE)`**:\n",
        "        *   Aqui, criamos uma instância do `DecisionTreeClassifier`. Esta é a classe em `sklearn.tree` que implementa o algoritmo da Árvore de Decisão. O parâmetro `random_state` é usado para garantir a reprodutibilidade dos resultados, ou seja, se você executar o código várias vezes com o mesmo `random_state`, a árvore gerada será sempre a mesma.\n",
        "\n",
        "2.  **Treino do Modelo**:\n",
        "    *   **`dt.fit(X_train, y_train)`**:\n",
        "        *   Este passo é onde o modelo \"aprende\". O algoritmo da Árvore de Decisão analisa os dados de treino (`X_train`) e os respetivos rótulos (`y_train`) para construir a estrutura da árvore, identificando as melhores divisões (splits) em cada nó para otimizar a classificação da variável alvo `attack_detected`.\n",
        "\n",
        "3.  **Visualização da Árvore de Decisão**:\n",
        "    *   **`plot_tree(dt, feature_names=X.columns, class_names=[str(c) for c in sorted(y.unique())], filled=True, rounded=True)`**:\n",
        "        *   A função `plot_tree` da `sklearn.tree` é utilizada para desenhar graficamente a árvore de decisão que acabámos de treinar. Esta visualização é extremamente útil para inspecionar as regras que o modelo aprendeu.\n",
        "        *   **`feature_names=X.columns`**: Atribui os nomes das colunas de `X` (as features) a cada nó da árvore, tornando mais fácil entender qual feature está a ser usada para dividir os dados.\n",
        "        *   **`class_names=[str(c) for c in sorted(y.unique())]`**: Atribui os nomes das classes da variável alvo (0 e 1, que representam \"sem ataque\" e \"com ataque\") aos nós da árvore.\n",
        "        *   **`filled=True`**: Colore os nós da árvore com base na classe predominante naquele nó, com a intensidade da cor indicando a proporção de amostras daquela classe.\n",
        "        *   **`rounded=True`**: Arredonda as bordas dos retângulos dos nós para uma estética melhor.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Nota:\n",
        "Para árvores de decisão sem restrições de profundidade, como esta, a visualização pode resultar numa imagem extremamente grande e difícil de interpretar, pois a árvore pode ter aprendido regras muito específicas e complexas (o que pode levar a overfitting). Em muitos casos, limita-se a profundidade da árvore (`max_depth`) para facilitar a visualização e promover a generalização do modelo."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "try:\n",
        "    # Use 'features.columns' instead of 'X.columns'\n",
        "    plot_tree(dt, feature_names=x.columns, class_names=[str(c) for c in sorted(y.unique())], filled=True, rounded=True)\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print('Tree plotting failed:', e)"
      ],
      "metadata": {
        "id": "4FXmv_j4w361"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of the tree model dt_classifier\n",
        "# (max_depth=3)\n",
        "dt_small = DecisionTreeClassifier(max_depth=3, random_state=RANDOM_STATE)\n",
        "dt_small.fit(X_train, y_train)\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "# Use 'features.columns' instead of 'X.columns'\n",
        "plot_tree(dt_small, feature_names=x.columns, class_names=[str(c) for c in sorted(y.unique())], filled=True, rounded=True)\n",
        "\n",
        "plt.title('Shallow Decision Tree (max_depth=3)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U1Digz-zRSpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dff3a6c7"
      },
      "source": [
        "### 2.6.3 Avaliação do Modelo Decision Tree (Conjunto de Teste)\n",
        "\n",
        "Esta célula tem como objetivo avaliar o desempenho do modelo `DecisionTreeClassifier` treinado anteriormente, utilizando o conjunto de dados de teste (`X_test`, `y_test`). A avaliação é feita através de métricas de classificação padrão:\n",
        "\n",
        "1.  **`y_pred = dt.predict(X_test)`**:\n",
        "    *   O modelo de Árvore de Decisão (`dt`) é usado para fazer previsões (`y_pred`) sobre a classe (`attack_detected`) dos dados no conjunto de teste (`X_test`).\n",
        "\n",
        "2.  **`accuracy = accuracy_score(y_test, y_pred)`**:\n",
        "    *   Calcula a **precisão (accuracy)** do modelo, que é a proporção de previsões corretas (tanto ataques corretamente detetados quanto não-ataques corretamente identificados) em relação ao total de amostras no conjunto de teste. Uma alta precisão indica que o modelo acerta na maioria das suas previsões.\n",
        "\n",
        "3.  **`print(classification_report(y_test, y_pred))`**:\n",
        "    *   Gera um **relatório de classificação** detalhado, que inclui:\n",
        "        *   **Precision (Precisão)**: Das amostras que o modelo previu como sendo de uma determinada classe, quantas realmente pertenciam a essa classe.\n",
        "        *   **Recall (Sensibilidade/Cobertura)**: Das amostras que realmente pertenciam a uma determinada classe, quantas foram corretamente identificadas pelo modelo.\n",
        "        *   **F1-Score**: A média harmónica da precisão e do recall, útil para avaliar o modelo quando há um desequilíbrio entre as classes.\n",
        "        *   **Support (Suporte)**: O número de ocorrências reais de cada classe no conjunto de teste.\n",
        "    *   Este relatório é crucial para entender o desempenho do modelo em cada classe (0 para não-ataque, 1 para ataque), especialmente em cenários onde uma classe pode ser mais importante ou menos frequente que a outra.\n",
        "\n",
        "4.  **Matriz de Confusão (`confusion_matrix`)**:\n",
        "    *   **`cm = confusion_matrix(y_test, y_pred)`**: Calcula a matriz de confusão, que é uma tabela que descreve o desempenho de um modelo de classificação em um conjunto de dados de teste, para o qual os valores verdadeiros são conhecidos.\n",
        "    *   **`sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ...)`**: Visualiza a matriz de confusão utilizando um heatmap, facilitando a interpretação. Os elementos da matriz são:\n",
        "        *   **True Positives (TP)**: Ataques corretamente previstos como ataques (canto inferior direito).\n",
        "        *   **True Negatives (TN)**: Não-ataques corretamente previstos como não-ataques (canto superior esquerdo).\n",
        "        *   **False Positives (FP)**: Não-ataques incorretamente previstos como ataques (erro Tipo I - alarme falso) (canto superior direito).\n",
        "        *   **False Negatives (FN)**: Ataques incorretamente previstos como não-ataques (erro Tipo II - ataque não detetado) (canto inferior esquerdo).\n",
        "    *   A matriz de confusão é fundamental para entender os tipos de erros que o modelo está a cometer, o que é especialmente importante em deteção de intrusões, onde FNs (não detetar um ataque real) podem ter consequências graves."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assess the model\n",
        "y_pred = dt.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Classification Report\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Decision Tree - Confusion Matrix (Test Set)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "It1BzKy--trJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f181119e"
      },
      "source": [
        "### 2.6.4 Random Forest - Model building\n",
        "\n",
        "Nesta secção, vamos construir e avaliar o nosso primeiro modelo de `RandomForestClassifier` com os seus parâmetros padrão, utilizando o conjunto de dados de treino e testando o seu desempenho no conjunto de teste.\n",
        "\n",
        "1.  **Instanciação do Modelo Random Forest**:\n",
        "    *   **`rf_model = RandomForestClassifier(random_state=RANDOM_STATE)`**: Criamos uma instância do `RandomForestClassifier`. O `random_state` é utilizado para garantir que os resultados do modelo sejam consistentes e reproduzíveis sempre que o código for executado.\n",
        "\n",
        "2.  **Treino do Modelo**:\n",
        "    *   **`rf_model.fit(X_train, y_train)`**: Este é o passo onde o modelo \"aprende\" os padrões e relações nos dados. O algoritmo Random Forest constrói múltiplas árvores de decisão com base nos `X_train` (features) e `y_train` (variável alvo).\n",
        "\n",
        "3.  **Realização de Previsões**:\n",
        "    *   **`y_pred_rf = rf_model.predict(X_test)`**: Após o treino, o modelo é usado para prever a classe (`attack_detected`) para as amostras no conjunto de teste (`X_test`), dados que o modelo nunca viu durante o treino.\n",
        "\n",
        "4.  **Avaliação do Desempenho**:\n",
        "    *   **`accuracy_rf = accuracy_score(y_test, y_pred_rf)`**: Calcula a precisão (accuracy) do modelo no conjunto de teste, que é a proporção de previsões corretas.\n",
        "    *   **`print(classification_report(y_test, y_pred_rf))`**: Gera um relatório detalhado com métricas como Precision, Recall, F1-Score e Support para cada classe (0 e 1). Este relatório é fundamental para entender o desempenho do modelo em identificar cada tipo de sessão (normal vs. ataque).\n",
        "    *   **Matriz de Confusão (`confusion_matrix`)**: A matriz de confusão (`cm_rf`) é visualizada para mostrar o número de True Positives, True Negatives, False Positives e False Negatives, fornecendo uma visão clara dos tipos de erros que o modelo está a cometer.\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Nota:\n",
        " Esta avaliação serve como uma **linha de base** para o desempenho do `RandomForestClassifier` antes de qualquer otimização ou ajuste de hiperparâmetros. Ela ajuda a entender o desempenho inicial do modelo com suas configurações padrão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c14b5ce"
      },
      "source": [
        "# Instantiate a default Random Forest Classifier\n",
        "rf_model = RandomForestClassifier(random_state=RANDOM_STATE)\n",
        "\n",
        "# Train the model on the training data\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Calculate Accuracy Score\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"Random Forest - Test Accuracy: {accuracy_rf * 100:.2f}%\")\n",
        "\n",
        "# Print Classification Report\n",
        "print(\"\\nRandom Forest - Test Set Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', xticklabels=sorted(y.unique()), yticklabels=sorted(y.unique()))\n",
        "plt.title('Random Forest - Confusion Matrix (Test Set)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.7 Cross-validation"
      ],
      "metadata": {
        "id": "1pFoY6yaS74g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.7.1 Decision Tree - Model instantiation"
      ],
      "metadata": {
        "id": "UY7AVmfRsnBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data\n",
        "feature_names = x.columns.tolist()\n",
        "features = x\n",
        "\n",
        "target = y\n",
        "target_names = [str(c) for c in sorted(y.unique())]\n",
        "\n",
        "print('Features:', feature_names, 'Classes:', target_names)\n",
        "\n",
        "# Instantiate the model\n",
        "cv_classifier = DecisionTreeClassifier(random_state=RANDOM_STATE)"
      ],
      "metadata": {
        "id": "jWYxjiYjS6tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree - Model assessment"
      ],
      "metadata": {
        "id": "5oxOkmDxWSEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using cross validation\n",
        "acc_score = cross_val_score(cv_classifier, features, target, cv=10)\n",
        "print(\"CV Mean Accuracy: %0.3f (+/- %0.3f)\" % (acc_score.mean(), acc_score.std()) )\n",
        "\n",
        "f1_score = cross_val_score(cv_classifier, features, target, cv=10, scoring='f1_macro')\n",
        "print(\"CV Mean F1: %0.3f (+/- %0.3f)\" % (np.mean(f1_score), np.std(f1_score)) )"
      ],
      "metadata": {
        "id": "wTh4PYW5UdET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree - Model deployment"
      ],
      "metadata": {
        "id": "JJhP9inwXH56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model with the complete data\n",
        "final_classifier = cv_classifier.fit(features, target)"
      ],
      "metadata": {
        "id": "BfRlpk5CWqB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on new data\n",
        "# X_new must have the same number of features as the training data (X)\n",
        "# We'll create a sample X_new with all zeros for demonstration, matching the 13 features\n",
        "X_new = pd.DataFrame(0, index=[0], columns=features.columns)\n",
        "\n",
        "# X_new['network_packet_size'] = 500\n",
        "# X_new['login_attempts'] = 2\n",
        "# X_new['protocol_type_TCP'] = 1 # Assuming TCP\n",
        "# X_new['failed_logins'] = 5\n",
        "# X_new['ip_reputation_score'] = 0.9\n",
        "\n",
        "prediction = final_classifier.predict(X_new)\n",
        "print(\"Prediction:\", prediction)"
      ],
      "metadata": {
        "id": "-JBFogyOUitH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model assessment: Precision Recall scores and Confusion matrix\n",
        "print(\"Precision, Recall, Confusion matrix\")\n",
        "print(classification_report(target, final_classifier.predict(features), digits=3))\n",
        "\n",
        "cm = confusion_matrix(target, final_classifier.predict(features))\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=sorted(y.unique()), yticklabels=sorted(y.unique()))\n",
        "plt.title('Final Classifier - Confusion Matrix (Training Set)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wG-A0MHmXgtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ffd0f2f"
      },
      "source": [
        "### Fixing Overfitting: Using `max_depth` in Decision Trees\n",
        "\n",
        "To mitigate overfitting in a Decision Tree, we can limit its complexity. A common way is to set the `max_depth` hyperparameter, which restricts how deep the tree can grow. This prevents the model from memorizing the training data too specifically.\n",
        "\n",
        "Let's train a new Decision Tree with a `max_depth` of, for example, 7, and compare its performance on both the training and test sets. We expect the training accuracy to be lower than 100%, but the test accuracy should be more representative and potentially higher than an unconstrained, overfit tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73f30c3f"
      },
      "source": [
        "# Instantiate a Decision Tree Classifier with a limited max_depth\n",
        "dt_fixed = DecisionTreeClassifier(min_samples_leaf = 10, max_depth=7, random_state=RANDOM_STATE)\n",
        "\n",
        "# Train the model on the training data\n",
        "dt_fixed.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on the training set\n",
        "y_train_pred_fixed = dt_fixed.predict(X_train)\n",
        "train_accuracy_fixed = accuracy_score(y_train, y_train_pred_fixed)\n",
        "print(f\"Fixed Decision Tree - Training Accuracy: {train_accuracy_fixed * 100:.2f}%\")\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_test_pred_fixed = dt_fixed.predict(X_test)\n",
        "test_accuracy_fixed = accuracy_score(y_test, y_test_pred_fixed)\n",
        "print(f\"Fixed Decision Tree - Test Accuracy: {test_accuracy_fixed * 100:.2f}%\")\n",
        "\n",
        "# Print classification report for the test set\n",
        "print(\"\\nFixed Decision Tree - Test Set Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred_fixed))\n",
        "\n",
        "# Plot Confusion Matrix for the test set\n",
        "cm_fixed_dt = confusion_matrix(y_test, y_test_pred_fixed)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm_fixed_dt, annot=True, fmt='d', cmap='Blues', xticklabels=sorted(y.unique()), yticklabels=sorted(y.unique()))\n",
        "plt.title('Fixed Decision Tree (max_depth=7) - Confusion Matrix (Test Set)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3465aa37"
      },
      "source": [
        "## Random Forest - Model instatiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0abad20"
      },
      "source": [
        "# Instantiate the Random Forest model for cross-validation\n",
        "rf_cv_classifier = RandomForestClassifier(random_state=RANDOM_STATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Radom Forest - Model assessment"
      ],
      "metadata": {
        "id": "SrkSb2AKtQ7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model using cross validation for accuracy\n",
        "rf_acc_score = cross_val_score(rf_cv_classifier, features, target, cv=10)\n",
        "print(\"Random Forest CV Mean Accuracy: %0.3f (+/- %0.3f)\" % (rf_acc_score.mean(), rf_acc_score.std()) )\n",
        "\n",
        "# Evaluate the model using cross validation for F1 score\n",
        "rf_f1_score = cross_val_score(rf_cv_classifier, features, target, cv=10, scoring='f1_macro')\n",
        "print(\"Random Forest CV Mean F1: %0.3f (+/- %0.3f)\" % (np.mean(rf_f1_score), np.std(rf_f1_score)) )"
      ],
      "metadata": {
        "id": "VzeA6cowtiwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest - Model deployment"
      ],
      "metadata": {
        "id": "wnB1bqJwtdtT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auto-generated-id-3"
      },
      "source": [
        "# Train the final Random Forest model on the complete data\n",
        "final_rf_classifier = RandomForestClassifier(random_state=RANDOM_STATE)\n",
        "final_rf_classifier.fit(features, target)\n",
        "\n",
        "print(\"Final Random Forest model trained on full dataset.\")\n",
        "\n",
        "# Make predictions on new data using the final Random Forest model\n",
        "prediction_rf = final_rf_classifier.predict(X_new)\n",
        "print(f\"Prediction for new data using Random Forest: {prediction_rf}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auto-generated-id-4"
      },
      "source": [
        "# Model assessment: Precision Recall scores and Confusion matrix (on training data)\n",
        "\n",
        "print(\"\\nRandom Forest - Training Set Precision, Recall, Confusion matrix:\")\n",
        "print(classification_report(target, final_rf_classifier.predict(features), digits=3))\n",
        "\n",
        "cm_rf_deployment = confusion_matrix(target, final_rf_classifier.predict(features))\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm_rf_deployment, annot=True, fmt='d', cmap='Blues', xticklabels=sorted(y.unique()), yticklabels=sorted(y.unique()))\n",
        "plt.title('Final Random Forest Classifier - Confusion Matrix (Training Set)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1068943b"
      },
      "source": [
        "### 2.5.3 Otimização do Modelo (com `max_depth`)\n",
        "\n",
        "Embora Random Forests sejam menos propensos a overfitting que árvores individuais, limitar a profundidade máxima das árvores constituintes (`max_depth`) pode melhorar a generalização e reduzir o tempo de treino, especialmente se as árvores padrão forem muito profundas.\n",
        "\n",
        "Sendo assim, iremos treinar e avaliar um modelo Random Forest com `max_depth` limitado a 7."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auto-generated-id-6"
      },
      "source": [
        "# Instantiate a Random Forest Classifier with a limited max_depth for its estimators\n",
        "rf_fixed = RandomForestClassifier(max_depth=7, random_state=RANDOM_STATE)\n",
        "\n",
        "# Train the model on the training data\n",
        "rf_fixed.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on the training set\n",
        "y_train_pred_rf_fixed = rf_fixed.predict(X_train)\n",
        "train_accuracy_rf_fixed = accuracy_score(y_train, y_train_pred_rf_fixed)\n",
        "print(f\"Fixed Random Forest - Training Accuracy: {train_accuracy_rf_fixed * 100:.2f}%\")\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_test_pred_rf_fixed = rf_fixed.predict(X_test)\n",
        "test_accuracy_rf_fixed = accuracy_score(y_test, y_test_pred_rf_fixed)\n",
        "print(f\"Fixed Random Forest - Test Accuracy: {test_accuracy_rf_fixed * 100:.2f}%\")\n",
        "\n",
        "# Print classification report for the test set\n",
        "print(\"\\nFixed Random Forest - Test Set Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred_rf_fixed))\n",
        "\n",
        "# Plot Confusion Matrix for the test set\n",
        "cm_fixed_rf = confusion_matrix(y_test, y_test_pred_rf_fixed)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm_fixed_rf, annot=True, fmt='d', cmap='Blues', xticklabels=sorted(y.unique()), yticklabels=sorted(y.unique()))\n",
        "plt.title('Fixed Random Forest (max_depth=7) - Confusion Matrix (Test Set)')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "736578c9"
      },
      "source": [
        "---\n",
        "# 3. **CONCLUSÃO**\n",
        "\n",
        "## 3.1 Geral\n",
        "Esta secção resume as descobertas do projeto e descreve as direções futuras.\n",
        "\n",
        "O projeto implementou e avaliou com sucesso modelos de Árvore de Decisão e Random Forest para deteção de intrusões em cibersegurança. Ambos os modelos demonstraram um bom desempenho, com o Random Forest a apresentar uma precisão superior e um F1-score no conjunto de teste, indicando a sua robustez na identificação de cenários de ataque e não ataque. A engenharia de características, particularmente a codificação de variáveis categóricas e a análise de correlação e distribuição, foi crucial na preparação dos dados para um treino eficaz do modelo. Preditoras-chave identificadas, como `failed_logins` e `ip_reputation_score`, revelaram-se altamente influentes na distinção de atividades maliciosas.\n",
        "\n",
        "## 3.2 Desafios e soluções\n",
        "**Desafios:**\n",
        "- **Desequilíbrio de Dados:** Um potencial desequilíbrio entre instâncias de ataque e não ataque foi um desafio que exigiu métricas de avaliação cuidadosas (como o F1-score) além da simples precisão.\n",
        "- **Overfitting em Árvores de Decisão:** Os modelos iniciais de Árvore de Decisão sem restrições de profundidade exibiram 100% de precisão no treino, mas menor precisão no teste, indicando overfitting.\n",
        "- **Interpretabilidade vs. Desempenho:** Embora as Árvores de Decisão ofereçam alta interpretabilidade, os Random Forests proporcionaram um melhor desempenho geral, mas são menos diretos de interpretar diretamente.\n",
        "\n",
        "**Soluções:**\n",
        "- **Divisão Estratificada:** Usou-se `stratify=y` em `train_test_split` para manter a distribuição das classes nos conjuntos de treino e teste.\n",
        "- **Parâmetro `max_depth`:** Limitou-se a `max_depth` das Árvores de Decisão para prevenir o overfitting, levando a uma melhor generalização em dados não vistos.\n",
        "- **Métodos de Ensemble:** Empregou-se Random Forest para aproveitar o poder de múltiplas árvores, mitigando as fraquezas das árvores individuais e melhorando o poder preditivo geral.\n",
        "\n",
        "## 3.3 Perspetivas Futuras\n",
        "Trabalhos futuros poderiam envolver:\n",
        "- **Otimização de Hiperparâmetros:** Otimização adicional dos hiperparâmetros da Árvore de Decisão e do Random Forest usando técnicas como GridSearchCV ou RandomizedSearchCV para potencialmente alcançar um desempenho ainda maior.\n",
        "- **Engenharia de Características Avançada:** Exploração de características mais complexas ou termos de interação (e.g., combinando `login_attempts` com `unusual_time_access`).\n",
        "- **Outros Modelos:** Investigação de outros algoritmos de machine learning, como Gradient Boosting Machines (XGBoost, LightGBM) ou redes neurais para comparação.\n",
        "- **Deteção em Tempo Real:** Adaptação dos modelos para deteção de intrusões em tempo real, considerando dados de streaming e abordagens de aprendizagem incremental.\n",
        "\n",
        "## 3.4 Em retrospetiva\n",
        "O processo destacou a importância de uma análise exploratória de dados (EDA) aprofundada para entender as distribuições e correlações das características. A Árvore de Decisão inicial não restrita serviu como uma lição valiosa na identificação e abordagem do overfitting. O desempenho robusto do modelo Random Forest sublinha a eficácia da aprendizagem por conjunto em tarefas de classificação complexas, como a deteção de intrusões em cibersegurança. A clara interpretabilidade da função `plot_tree` para árvores rasas também foi benéfica para a compreensão das regras básicas de decisão.\n",
        "\n",
        "<br>\n",
        "\n",
        "Obrigado, Professor Joaquim :)"
      ]
    }
  ]
}