{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Fundamentals of Artificial Intelligence**\n",
        "\n",
        "## MSc in Applied Artificial Intelligence 2025/2026 <br>\n",
        "## Group 02 - Project 2 - K-Means\n",
        "| Nome                              | Número de Aluno |\n",
        "|-----------------------------------|------------:|\n",
        "| Adelino Daniel da Rocha Vilaça    | a16939          |\n",
        "| António Jorge Magalhães da Rocha  | a26052          |"
      ],
      "metadata": {
        "id": "cpmFml6A8N0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 0. - **INTRODUCTION**"
      ],
      "metadata": {
        "id": "goPIYBHH9AH8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.1 - Goal\n",
        "> This project aims to explore and demonstrate the application of K-Means clustering, an unsupervised machine learning algorithm, on a cybersecurity intrusion detection dataset. We will compare two distinct approaches: one where the `attack_detected` attribute is included as a feature during clustering, and another where it is explicitly excluded. The primary objective is to understand how feature selection, particularly the inclusion or exclusion of the target variable, impacts the ability of K-Means to identify meaningful patterns and groupings related to network intrusions.\n",
        "\n",
        "## 0.2 - Environment\n",
        "> This notebook is developed and executed within the Google Colaboratory (Colab) environment, a free cloud-based Jupyter Notebook service. Colab provides access to computational resources, including GPUs, and pre-installed libraries, making it an ideal platform for machine learning experimentation without local setup requirements. The development leverages Python 3 and standard data science libraries such as Pandas for data manipulation, NumPy for numerical operations, Matplotlib and Seaborn for data visualization, and Scikit-learn for machine learning algorithms, particularly K-Means clustering and data preprocessing tools like `StandardScaler`.\n",
        "\n",
        "## 0.3 - Definitions\n",
        "\n",
        "> * **K-Means Clustering**: An unsupervised machine learning algorithm that partitions `n` observations into `k` clusters, where each observation belongs to the cluster with the nearest mean (centroid), serving as a prototype of the cluster.\n",
        "> * **Inertia (Elbow Method)**: A metric used in K-Means to measure the within-cluster sum of squares. It decreases as `k` increases. The 'elbow' point in the plot of inertia vs. `k` suggests an optimal `k`.\n",
        "> * **Silhouette Score**: A metric to evaluate the quality of clusters created by clustering algorithms. It measures how similar an object is to its own cluster compared to other clusters. Scores range from -1 (poor clustering) to +1 (dense, well-separated clusters).\n",
        "> * **StandardScaler**: A preprocessing technique that standardizes features by removing the mean and scaling to unit variance, ensuring all features contribute equally to distance-based algorithms like K-Means.\n",
        "> * **One-Hot Encoding**: A technique to convert categorical variables into a numerical format that machine learning algorithms can understand. Each category is transformed into a new binary column.\n",
        "> * **`attack_detected`**: The target variable in our cybersecurity dataset, indicating whether a network intrusion (1) or normal activity (0) was detected during a session."
      ],
      "metadata": {
        "id": "UucbrAS09AsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 1. - **AGENT DESIGN**"
      ],
      "metadata": {
        "id": "SamOE4gG9Ckk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unsupervised Learning — K-MEANS\n",
        "\n",
        "This notebook presents examples of the use of well-known unsupervised learning algorithms.\n",
        "\n",
        "### K-Means clustering\n",
        "Steps:\n",
        "* load the titanic dataset\n",
        "* do some EDA visualizations/analysis\n",
        "* prepare the dataset\n",
        "* K hyperparameter tunning\n",
        "* apply the model\n"
      ],
      "metadata": {
        "id": "R-9_2Haa3Nln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 - Platforms"
      ],
      "metadata": {
        "id": "XaMucKFb9EDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1.1 - Jupyter Notebook <br>\n",
        " > A Jupyter Notebook is an open-source web application that allows creating and sharing documents containing live code, equations, visualizations, and narrative text. It's widely used in data science, machine learning, and scientific computing for interactive development, exploration, and documentation.\n",
        "\n",
        "### 1.1.2 - Google Colaboratory <br>\n",
        "  >Free cloud-based service that provides a hosted Jupyter Notebook environment. It allows writing and executing code in a browser for free and without any setup."
      ],
      "metadata": {
        "id": "3YrJKnQ49Fak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Packages and Libraries\n"
      ],
      "metadata": {
        "id": "ia8AD4ce9G2Q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa50cfdf"
      },
      "source": [
        "### 1.2.1 Packages and Libraries\n",
        "\n",
        "This notebook utilizes several key Python libraries for data manipulation, machine learning, and visualization:\n",
        "\n",
        "*   **`pandas`**: For data manipulation and analysis, particularly for handling DataFrames.\n",
        "*   **`numpy`**: For numerical operations, especially with arrays.\n",
        "*   **`matplotlib.pyplot`**: For creating static, interactive, and animated visualizations in Python.\n",
        "*   **`seaborn`**: A data visualization library based on matplotlib, providing a high-level interface for drawing attractive and informative statistical graphics.\n",
        "*   **`sklearn.cluster.KMeans`**: The K-Means clustering algorithm from scikit-learn.\n",
        "*   **`sklearn.preprocessing.StandardScaler`**: For standardizing features by removing the mean and scaling to unit variance.\n",
        "*   **`sklearn.metrics`**: For evaluating model performance, specifically for `silhouette_score`.\n",
        "\n",
        "These libraries collectively enable the data loading, preprocessing, K-Means clustering, and visual analysis presented in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "itiL0rzHqkCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the data"
      ],
      "metadata": {
        "id": "2eLC8tFTaDI5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "627fb0c4"
      },
      "source": [
        "### Usage of `kaggle.json`\n",
        "\n",
        "The `kaggle.json` file serves as an essential **authentication token** for interacting with the Kaggle API (Kaggle Application Programming Interface). It securely stores the user's Kaggle credentials, including their username and key."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # kaggle.json"
      ],
      "metadata": {
        "id": "P7kytrCkpTCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Token Permissions"
      ],
      "metadata": {
        "id": "oO7LpjTxeorE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "dE4VHDzud0pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list | head"
      ],
      "metadata": {
        "id": "gVqBil5wd6wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 DATASET\n",
        "\n",
        "\n",
        "### 1.3.1 Used Dataset\n",
        "\n",
        "> This dataset, named `cybersecurity_intrusion_data.csv`, focuses on **cybersecurity intrusion detection**.\n",
        "\n",
        "* It contains information about network sessions, such as packet size, protocol type, session duration, and login attempts.\n",
        "* It includes details about user behavior, such as browser type and failed login attempts.\n",
        "* The main objective is to classify whether a given session indicates an `attack_detected` (attack detected) or not, with this being the target variable."
      ],
      "metadata": {
        "id": "FkMZuZYt7ZgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d dnkumars/cybersecurity-intrusion-detection-dataset -p /content/ --unzip"
      ],
      "metadata": {
        "id": "65QA6Q7LeJZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the file\n",
        "dataset = pd.read_csv('cybersecurity_intrusion_data.csv')\n",
        "df = dataset\n",
        "dataset_data = pd.DataFrame(dataset)\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "dataset_data.head()"
      ],
      "metadata": {
        "id": "rQx3dGRPqsGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data\n",
        "# Exclude 'session_id' and 'attack_detected' from the feature set\n",
        "cyber_feature_names = df.drop(columns=['session_id', 'attack_detected']).columns.tolist()\n",
        "cyber_data = df[cyber_feature_names]\n",
        "\n",
        "# Set 'attack_detected' as the label_data\n",
        "label_data = df['attack_detected']\n",
        "label_names = list(set(label_data))\n",
        "\n",
        "print('Features:', cyber_feature_names, '   Classes:', label_names)"
      ],
      "metadata": {
        "id": "GyNknF87Z-kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA visualizations/analysis"
      ],
      "metadata": {
        "id": "f79xExXtcmLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EDA analysis\n",
        "print(dataset_data.info())\n",
        "print(dataset_data.describe())"
      ],
      "metadata": {
        "id": "hPNrkjNarJJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da86b0eb"
      },
      "source": [
        "# Visualizations for Cybersecurity Data\n",
        "# Selecting key numerical features from the cybersecurity dataset and 'attack_detected' for hue\n",
        "numerical_features_cyber = ['network_packet_size', 'session_duration', 'ip_reputation_score', 'failed_logins']\n",
        "v_features_cyber = dataset_data[numerical_features_cyber + ['attack_detected']]\n",
        "\n",
        "sns.pairplot(v_features_cyber, hue='attack_detected')\n",
        "plt.suptitle('Pairplot of Selected Numerical Features by Attack Detection', y=1.02) # Add a suptitle for clarity\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Clustering WITH `attack_detected` attribute"
      ],
      "metadata": {
        "id": "yOkX5CYQwBtT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preparation"
      ],
      "metadata": {
        "id": "gkMsY8ezhmrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a copy of the raw data to work with\n",
        "df_cyber_temp = dataset_data.copy()\n",
        "\n",
        "# Remove the 'session_id' column as it's not a feature for clustering\n",
        "df_cyber_temp = df_cyber_temp.drop(columns=['session_id'])\n",
        "\n",
        "# Identify categorical columns including 'attack_detected' for one-hot encoding\n",
        "columns_to_encode = df_cyber_temp.select_dtypes(include='object').columns.tolist()\n",
        "# Add 'attack_detected' as it's treated as a categorical feature here\n",
        "if 'attack_detected' not in columns_to_encode and 'attack_detected' in df_cyber_temp.columns:\n",
        "    columns_to_encode.append('attack_detected')\n",
        "\n",
        "# One-hot encode the identified categorical features\n",
        "cyber_data_with_labels_as_features = pd.get_dummies(df_cyber_temp, columns=columns_to_encode, drop_first=False)\n",
        "\n",
        "# Display the updated DataFrame with one-hot encoded features\n",
        "print(\"DataFrame with one-hot encoded labels as features:\")\n",
        "print(cyber_data_with_labels_as_features.head())"
      ],
      "metadata": {
        "id": "iNsIMFMwLiLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant features (all columns from the processed dataframe)\n",
        "# The cyber_data_with_labels_as_features dataframe already contains all desired features, including\n",
        "# the one-hot encoded 'attack_detected'\n",
        "cyber_features_with_labels = cyber_data_with_labels_as_features.copy()\n",
        "\n",
        "# Get all column names to retain after scaling\n",
        "all_cyber_features_with_labels = cyber_features_with_labels.columns.values.tolist()\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "cyber_scaled_with_labels = scaler.fit_transform(cyber_features_with_labels)\n",
        "cyber_scaled_with_labels = pd.DataFrame(cyber_scaled_with_labels, columns=all_cyber_features_with_labels)\n",
        "\n",
        "# Display the head of the scaled data\n",
        "print(\"Scaled data with 'attack_detected' as features:\")\n",
        "print(cyber_scaled_with_labels.head())"
      ],
      "metadata": {
        "id": "IESDmTmTrRIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K hyperparameter tuning"
      ],
      "metadata": {
        "id": "Y-8uvoTwh673"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore cluster table\n",
        "cyber_scaled_with_labels = cyber_scaled_with_labels.drop(columns=['cluster'], errors='ignore')\n",
        "\n",
        "# Test k values from 2 to 10\n",
        "inertia = []\n",
        "silhouette_scores = []\n",
        "k_values = range(2, 11)\n",
        "\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=1234, n_init=10) # Added n_init for modern KMeans\n",
        "    kmeans.fit(cyber_scaled_with_labels)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "    silhouette_scores.append(metrics.silhouette_score(cyber_scaled_with_labels, kmeans.labels_))\n",
        "\n",
        "plt.plot(k_values, inertia, marker='o')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Elbow Method for Optimal k (Cybersecurity Data)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9lEBlSOWiGRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff861712"
      },
      "source": [
        "### Interpreting K-Means Hyperparameter Tuning Results\n",
        "\n",
        "#### 1. Elbow Method (Inertia Plot)\n",
        "\n",
        "*   **Observation**: You noted a significant drop in inertia from `k=8` to `k=9`, and a smaller, but still noticeable, drop from `k=4` to `k=5`.\n",
        "*   **Interpretation**: The 'elbow' in the inertia plot typically indicates the point of diminishing returns. The most pronounced drop from `k=8` to `k=9` suggests that moving from 8 to 9 clusters provides a substantial improvement in explaining the variance within the data, making `k=9` a strong candidate for the optimal number of clusters. While a drop from `k=4` to `k=5` is also observed, it's generally less pronounced than the initial steep decline, meaning the 'benefit' of adding that extra cluster might be less significant compared to the earlier ones.\n",
        "\n",
        "#### 2. Silhouette Score Plot\n",
        "\n",
        "*   **Observation**: We also need to consider the Silhouette Score plot, which measures how similar an object is to its own cluster (cohesion) compared to other clusters (separation). Higher scores indicate better-defined and more separated clusters.\n",
        "*   **Interpretation**: A peak in the Silhouette Score indicates the `k` value for which clusters are most distinct. We should examine this plot to see which `k` value provides the highest score. If `k=9` (or `k=6`) also shows a relatively high or peak silhouette score, it would further support its choice as the optimal number of clusters.\n",
        "\n",
        "Considering both plots together helps in making a more informed decision for `optimal_k`. The `k=9` appears to be a strong candidate due to the initial steep drop in inertia."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Silhouette\n",
        "plt.plot(k_values, silhouette_scores, marker='o')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score for Optimal k')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aoKFs3I2reZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63628cac"
      },
      "source": [
        "### Interpreting the K-Means Clustering Results\n",
        "\n",
        "After applying the K-Means algorithm with `optimal_k = 9`, a new column named `'cluster'` has been added to your original `dataset_data` DataFrame. This column indicates which of the clusters each cybersecurity session has been assigned to by the K-Means model.\n",
        "\n",
        "*   **`session_id`**: The unique identifier for each session.\n",
        "*   **Original Features**: All the original features (`network_packet_size`, `protocol_type`, `login_attempts`, etc.) are still present, as they were the input to the clustering process.\n",
        "*   **`cluster`**: This is the new column, where each row (cybersecurity session) now has a value (0 to 9) representing the cluster it belongs to. These cluster assignments are based on the similarity of the session's features, as determined by the K-Means algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply the model"
      ],
      "metadata": {
        "id": "4aUc9s3PjS8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose optimal k based on the plots (example)\n",
        "optimal_k = 9\n",
        "\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "clusters = kmeans.fit_predict(cyber_scaled_with_labels)\n",
        "\n",
        "# Add cluster assignment to dataset_data\n",
        "dataset_data['cluster'] = clusters\n",
        "dataset_data.head()"
      ],
      "metadata": {
        "id": "EfqTUT4Xrlbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53318809"
      },
      "source": [
        "### Interpreting the Cluster Composition Results (for optimal_k = 9)\n",
        "\n",
        "The `cluster_composition` table provides a crucial look into how the K-Means algorithm, with `optimal_k = 9`, has grouped your cybersecurity sessions relative to the actual `attack_detected` labels.\n",
        "\n",
        "<br>\n",
        "\n",
        "Here's what each part signifies:\n",
        "\n",
        "*   **`attack_detected 0`**: Represents network sessions where **no intrusion or attack was detected** (normal activity).\n",
        "*   **`attack_detected 1`**: Represents network sessions where **an intrusion or attack was detected** (malicious activity).\n",
        "\n",
        "Let's analyze each cluster:\n",
        "\n",
        "*   **Cluster 0**: This cluster is mixed, with `267` non-attack sessions and `195` attack sessions. It shows a slight dominance of normal activity but still contains a significant portion of attacks, suggesting these sessions share some characteristics that group them together, regardless of attack status.\n",
        "\n",
        "*   **Cluster 1**: This cluster is predominantly composed of attack sessions, with `0` non-attack sessions and `1520` attack sessions. This indicates that K-Means has successfully identified a group of sessions that are almost exclusively malicious activity.\n",
        "\n",
        "*   **Cluster 2**: This cluster is heavily skewed towards non-attack sessions, containing `999` instances where **no attack was detected** and `563` detected attacks. While not entirely pure, it largely represents normal traffic.\n",
        "\n",
        "*   **Cluster 3**: This cluster is quite mixed, with `790` non-attack sessions and `610` attack sessions. Similar to Cluster 0, this suggests a blend of characteristics that prevent a clear separation by K-Means.\n",
        "\n",
        "*   **Cluster 4**: This cluster is remarkably 'pure' for non-attack sessions, containing `851` instances where **no attack was detected** and `0` detected attacks. This indicates an effective grouping of a segment of normal network traffic.\n",
        "\n",
        "*   **Cluster 5**: This cluster is almost entirely composed of attack sessions, with `2` non-attack sessions and `815` detected attacks. This is another strong indicator of the algorithm successfully identifying and grouping malicious activities.\n",
        "\n",
        "*   **Cluster 6**: This cluster is another 'pure' group for non-attack sessions, with `1942` instances where **no attack was detected** and `0` detected attacks. This represents a significant portion of normal behavior.\n",
        "\n",
        "*   **Cluster 7**: This cluster is a mix, with `298` non-attack sessions and `194` attack sessions. It shows a higher proportion of non-attack sessions, but still includes a notable number of attacks.\n",
        "\n",
        "*   **Cluster 8**: This cluster shows a higher proportion of attack sessions, with `124` non-attack sessions and `367` attack sessions. While not entirely pure, it leans towards malicious activity.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Relevance of These Results\n",
        "\n",
        "These results are **highly relevant** and demonstrate that the K-Means model has done a very good job in identifying underlying structures within your cybersecurity data when the `attack_detected` attribute was included as a feature. Even though K-Means is an unsupervised algorithm, it has found natural groupings that strongly align with whether an attack was present or not.\n",
        "\n",
        "*   **Anomaly Detection**: The ability to isolate clusters (e.g., Cluster 1 and Cluster 5) almost entirely composed of attacks is a fantastic outcome for intrusion detection. It implies that these attack patterns are distinct enough to be recognized.\n",
        "*   **Normal Behavior Profiling**: Similarly, Cluster 4 and Cluster 6 give you strong profiles of 'normal' behavior. Any new session not falling into these clusters, especially if it resembles the attack-heavy clusters, would warrant further investigation.\n",
        "*   **Further Investigation**: Mixed clusters (e.g., Cluster 0, 2, 3, 7, 8) are also very important. They could point to:\n",
        "    *   Subtler attack vectors that are harder to distinguish.\n",
        "    *   New, unknown threats that haven't been clearly defined.\n",
        "    *   Normal traffic with unusual characteristics that mimic attacks.\n",
        "\n",
        "Overall, these clustering results provide valuable insights into the inherent separability of your cybersecurity data based on the features used. They lay a strong foundation for building more advanced intrusion detection systems, as you now have a good understanding of how different types of sessions group together."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze the composition of each cluster with respect to 'attack_detected'\n",
        "# This shows how many instances of attack_detected=0 and attack_detected=1 are in each cluster\n",
        "cluster_composition = dataset_data.groupby('cluster')['attack_detected'].value_counts().unstack(fill_value=0)\n",
        "\n",
        "print(\"Composition of each cluster by 'attack_detected' label:\")\n",
        "print(cluster_composition)"
      ],
      "metadata": {
        "id": "2wCYHTNHh6KR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counts 'attack_detected' labels per cluster and calculates metrics.\n",
        "def analyze_clusters(data, clusters):\n",
        "\n",
        "    # Calculate metrics\n",
        "    # Group by the 'cluster' assigned by K-Means and the actual 'attack_detected' label\n",
        "    cluster_attack_counts = data.groupby(['cluster', 'attack_detected']).size().unstack(fill_value=0)\n",
        "\n",
        "    cluster_stats = pd.DataFrame()\n",
        "    cluster_stats['cluster'] = cluster_attack_counts.index\n",
        "    cluster_stats['total_sessions_in_cluster'] = cluster_attack_counts.sum(axis=1)\n",
        "\n",
        "    # Iterate through unique 'attack_detected' values (0 and 1)\n",
        "    for attack_status in data['attack_detected'].unique():\n",
        "        col_name_count = f'attack_detected_{attack_status}_count'\n",
        "        col_name_proportion = f'attack_detected_{attack_status}_proportion'\n",
        "\n",
        "        cluster_stats[col_name_count] = cluster_attack_counts[attack_status]\n",
        "        cluster_stats[col_name_proportion] = cluster_attack_counts[attack_status] / cluster_stats['total_sessions_in_cluster']\n",
        "\n",
        "    return cluster_stats\n",
        "\n",
        "# Example usage with our cybersecurity dataset\n",
        "cluster_analysis = analyze_clusters(dataset_data, clusters)\n",
        "print(\"Detailed Cluster Analysis:\")\n",
        "cluster_analysis"
      ],
      "metadata": {
        "id": "osuKm_Lvfxbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f919857"
      },
      "source": [
        "### Interpreting Cluster Averages (for optimal_k = 9)\n",
        "\n",
        "This table displays the mean values for key numerical features within each of the nine identified clusters (0 through 8). By examining these averages, we can gain insights into the typical characteristics of sessions belonging to each group.\n",
        "\n",
        "Each row represents a cluster, and the columns show the average `network_packet_size`, `session_duration`, `ip_reputation_score`, and `failed_logins` for that cluster. This helps us to understand what differentiates the clusters in terms of these numerical attributes, complementing our understanding of their `attack_detected` composition:\n",
        "\n",
        "* **`network_packet_size`**: The average network packet sizes across clusters are fairly consistent, hovering around 500-515. Cluster 4 shows a slightly higher average, while Cluster 1 has a slightly lower average. This suggests that packet size might not be the primary distinguishing factor between these clusters.\n",
        "\n",
        "* **`session_duration`**: Similar to packet size, session durations are generally in the range of 770-850. Clusters 0, 1, and 5 show slightly longer session durations on average, with Cluster 5 having the highest. This could indicate certain types of activity (or attacks) that involve more prolonged interactions.\n",
        "\n",
        "* **`ip_reputation_score`**: This feature shows more variability. Clusters 1 and 5 (which were identified as being rich in `attack_detected=1` sessions) have higher average IP reputation scores (around 0.37). Conversely, clusters 4 and 6 (which were identified as primarily `attack_detected=0` sessions) have lower average IP reputation scores (around 0.29-0.30). This suggests that a higher IP reputation score might be correlated with attack sessions in this dataset.\n",
        "\n",
        "* **`failed_logins`**: This feature also shows interesting differences. Clusters 1 and 5, which are attack-heavy, exhibit the highest average number of failed logins (around 1.98). This is a strong indicator that failed login attempts are a key characteristic of the attack-related clusters. Clusters 4 and 6, on the other hand, have the lowest average failed logins (around 1.14-1.17), reinforcing their association with normal, non-attack behavior.\n",
        "\n",
        "### Conclusion from Averages\n",
        "\n",
        "By combining these numerical insights with the `attack_detected` composition analysis, we can build a richer profile for each cluster. For example:\n",
        "\n",
        "* **Attack-prone clusters (e.g., 1 and 5)** tend to have higher `ip_reputation_score` and significantly more `failed_logins`.\n",
        "* **Normal behavior clusters (e.g., 4 and 6)** are characterized by lower `ip_reputation_score` and fewer `failed_logins`.\n",
        "\n",
        "The relatively stable `network_packet_size` and `session_duration` averages across all clusters suggest that while these are important features, the `ip_reputation_score` and `failed_logins` are more discriminative in distinguishing between the types of activities grouped by K-Means."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group data by cluster and calculate the mean of key numerical features\n",
        "cluster_averages = dataset_data.groupby('cluster')[numerical_features_cyber].mean()\n",
        "\n",
        "# Display the results\n",
        "print(cluster_averages)"
      ],
      "metadata": {
        "id": "N6B3QMO1iflF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b50c728"
      },
      "source": [
        "### Visualizing Cluster Assignments\n",
        "\n",
        "This code generates a scatter plot to visualize how the K-Means algorithm has grouped your cybersecurity sessions into the `optimal_k = 3` clusters.\n",
        "\n",
        "*   **Code Explanation**:\n",
        "    *   `plt.figure(figsize=(10, 6))`: Sets up the size of the plot for better readability.\n",
        "    *   `for cluster_id in range(optimal_k)`: This loop iterates through each of the three clusters (0, 1, 2) that K-Means identified.\n",
        "    *   `cluster_data = dataset_data[dataset_data['cluster'] == cluster_id]`: For each iteration, it filters the original `dataset_data` to get only the sessions belonging to the current `cluster_id`.\n",
        "    *   `plt.scatter(cluster_data['network_packet_size'], cluster_data['session_duration'], label=f'Cluster {cluster_id}')`: This is the core plotting step. It creates a scatter plot using two key numerical features:\n",
        "        *   **`network_packet_size`**: The size of the network packets, plotted on the x-axis.\n",
        "        *   **`session_duration`**: The duration of the session, plotted on the y-axis.\n",
        "        Each cluster is plotted with a different color, and a label is assigned for the legend.\n",
        "    *   `plt.xlabel`, `plt.ylabel`, `plt.title`, `plt.legend()`, `plt.show()`: These lines add labels to the axes, a title to the plot, display a legend to identify which color corresponds to which cluster, and finally show the plot.\n",
        "\n",
        "*   **Interpreting the Results**:\n",
        "    *   This plot allows you to visually inspect the separation and characteristics of your clusters based on `Network Packet Size` and `Session Duration`.\n",
        "    *   You should observe if the clusters are distinct or if they overlap significantly in this 2D projection. Ideally, well-separated clusters would show clear groupings of points of the same color.\n",
        "    *   For example, if one cluster (e.g., Cluster 2, which we identified as being mostly `attack_detected=1`) tends to have very high `session_duration` and large `network_packet_size` compared to other clusters, this visualization will make that pattern evident. This helps you understand the defining characteristics of each cluster and why K-Means grouped the data in a particular way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14b73b31"
      },
      "source": [
        "### Visualizing Cluster Assignments (for optimal_k = 9)\n",
        "\n",
        "This code generates a scatter plot to visualize how the K-Means algorithm has grouped your cybersecurity sessions into the `optimal_k = 9` clusters.\n",
        "\n",
        "*   **Code Explanation**:\n",
        "    *   `plt.figure(figsize=(10, 6))`: Sets up the size of the plot for better readability.\n",
        "    *   `for cluster_id in range(optimal_k)`: This loop iterates through each of the nine clusters (0 through 8) that K-Means identified.\n",
        "    *   `cluster_data = dataset_data[dataset_data['cluster'] == cluster_id]`: For each iteration, it filters the original `dataset_data` to get only the sessions belonging to the current `cluster_id`.\n",
        "    *   `plt.scatter(cluster_data['network_packet_size'], cluster_data['session_duration'], label=f'Cluster {cluster_id}')`: This is the core plotting step. It creates a scatter plot using two key numerical features:\n",
        "        *   **`network_packet_size`**: The size of the network packets, plotted on the x-axis.\n",
        "        *   **`session_duration`**: The duration of the session, plotted on the y-axis.\n",
        "        Each cluster is plotted with a different color, and a label is assigned for the legend.\n",
        "    *   `plt.xlabel`, `plt.ylabel`, `plt.title`, `plt.legend()`, `plt.show()`: These lines add labels to the axes, a title to the plot, display a legend to identify which color corresponds to which cluster, and finally show the plot.\n",
        "\n",
        "*   **Interpreting the Results**:\n",
        "    *   This plot allows you to visually inspect the separation and characteristics of your clusters based on `Network Packet Size` and `Session Duration`.\n",
        "    *   You should observe if the clusters are distinct or if they overlap significantly in this 2D projection. Ideally, well-separated clusters would show clear groupings of points of the same color.\n",
        "    *   For example, if one cluster (e.g., Cluster 1 or 5, which we identified as being mostly `attack_detected=1`) tends to have very high `session_duration` and large `network_packet_size` compared to other clusters, this visualization will make that pattern evident. This helps you understand the defining characteristics of each cluster and why K-Means grouped the data in a particular way.\n",
        "\n",
        "    Given that we are now using `optimal_k=9` clusters, the visualization will likely show more granular groupings. It's important to see if the highly pure attack and non-attack clusters (like Cluster 1, 4, 5, and 6 from the `cluster_composition` analysis) form visually distinct groups in this 2D projection, or if their separation relies more on other features not visualized here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize cluster assignments for cybersecurity data\n",
        "plt.figure(figsize=(10, 6))\n",
        "for cluster_id in range(optimal_k):\n",
        "    cluster_data = dataset_data[dataset_data['cluster'] == cluster_id]\n",
        "    plt.scatter(cluster_data['network_packet_size'], cluster_data['session_duration'], label=f'Cluster {cluster_id}')\n",
        "\n",
        "plt.xlabel('Network Packet Size')\n",
        "plt.ylabel('Session Duration')\n",
        "plt.title('Cluster Assignments (Network Packet Size vs. Session Duration)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eEJWqrfenq6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Clustering WITHOUT `attack_detected` attribute"
      ],
      "metadata": {
        "id": "-_EnAFw5wZB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read the file and prepare data"
      ],
      "metadata": {
        "id": "k1n8k2jpwZB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a copy of the raw data to work with, removing 'session_id' and 'attack_detected'\n",
        "df_cyber_without_labels = dataset_data.drop(columns=['session_id', 'attack_detected'])\n",
        "\n",
        "# Identify categorical columns for one-hot encoding\n",
        "columns_to_encode_without_labels = df_cyber_without_labels.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# One-hot encode the identified categorical features\n",
        "cyber_data_without_labels = pd.get_dummies(df_cyber_without_labels, columns=columns_to_encode_without_labels, drop_first=False)\n",
        "\n",
        "# Display the updated DataFrame with one-hot encoded features\n",
        "print(\"DataFrame with one-hot encoded features, without 'attack_detected':\")\n",
        "print(cyber_data_without_labels.head())"
      ],
      "metadata": {
        "id": "QgOokp4qwZB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant features (all columns from the processed dataframe without labels)\n",
        "cyber_features_without_labels = cyber_data_without_labels.copy()\n",
        "\n",
        "# Get all column names to retain after scaling\n",
        "all_cyber_features_without_labels = cyber_features_without_labels.columns.values.tolist()\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "cyber_scaled_without_labels = scaler.fit_transform(cyber_features_without_labels)\n",
        "cyber_scaled_without_labels = pd.DataFrame(cyber_scaled_without_labels, columns=all_cyber_features_without_labels)\n",
        "\n",
        "# Display the head of the scaled data\n",
        "print(\"Scaled data without 'attack_detected' as features:\")\n",
        "print(cyber_scaled_without_labels.head())"
      ],
      "metadata": {
        "id": "EGk3MY6kwZB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K hyperparameter tuning"
      ],
      "metadata": {
        "id": "Il1RiP8owZB_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5225d7d"
      },
      "source": [
        "### Interpreting K-Means Hyperparameter Tuning Results (WITHOUT `attack_detected`)\n",
        "\n",
        "In this section, we are performing K-Means clustering without including the `attack_detected` attribute as a feature. The goal is to see if the algorithm can discover inherent groupings in the data based *only* on the other network and session characteristics. The interpretation of the Elbow Method and Silhouette Score plots remains similar, but the results might differ as K-Means now has to rely purely on the other features to find structure.\n",
        "\n",
        "#### 1. Elbow Method (Inertia Plot)\n",
        "\n",
        "*   **Observation**: You will look for a clear 'elbow' in the plot of inertia versus the number of clusters (`k`). This point signifies where adding more clusters no longer substantially decreases the within-cluster sum of squares, suggesting that additional clusters provide diminishing returns in explaining data variance.\n",
        "*   **Interpretation**: A sharp bend or 'elbow' suggests an optimal `k` where the clusters are reasonably tight and distinct.\n",
        "\n",
        "#### 2. Silhouette Score Plot\n",
        "\n",
        "*   **Observation**: This plot shows the `silhouette score` for each `k`. A higher silhouette score indicates better-defined clusters, meaning objects are well-matched to their own cluster and poorly matched to neighboring clusters.\n",
        "*   **Interpretation**: The `k` value corresponding to the *highest* silhouette score is often considered optimal as it indicates the best overall cluster quality (cohesion and separation).\n",
        "\n",
        "Considering both plots together helps in making a more informed decision for `optimal_k` for this purely unsupervised clustering scenario. We'll be looking for a balance between reducing inertia and maximizing cluster distinction."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test k values from 2 to 10\n",
        "inertia = []\n",
        "silhouette_scores = []\n",
        "k_values = range(2, 11)\n",
        "\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=1234, n_init=10) # Added n_init for modern KMeans\n",
        "    kmeans.fit(cyber_scaled_without_labels)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "    silhouette_scores.append(metrics.silhouette_score(cyber_scaled_without_labels, kmeans.labels_))\n",
        "\n",
        "plt.plot(k_values, inertia, marker='o')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Elbow Method for Optimal k (Cybersecurity Data WITHOUT attack_detected)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l-3peNtVwZCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply the model"
      ],
      "metadata": {
        "id": "KSTqQApXwZCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose optimal k based on the plots (example)\n",
        "optimal_k = 6\n",
        "\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "clusters_without_labels = kmeans.fit_predict(cyber_scaled_without_labels)\n",
        "\n",
        "# Add cluster assignment to a copy of the original dataset_data\n",
        "dataset_data_without_labels_clustering = dataset_data.copy()\n",
        "dataset_data_without_labels_clustering['cluster_without_labels'] = clusters_without_labels\n",
        "\n",
        "# Display the head of the dataset with new cluster assignments\n",
        "print(\"Dataset with new cluster assignments (without using 'attack_detected' as feature):\")\n",
        "dataset_data_without_labels_clustering.head()"
      ],
      "metadata": {
        "id": "N7F4wcB-wZCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counts 'attack_detected' labels per cluster and calculates metrics.\n",
        "def analyze_clusters(data, cluster_col_name, actual_label_col_name):\n",
        "\n",
        "    # Calculate metrics\n",
        "    # Group by the 'cluster' assigned by K-Means and the actual 'attack_detected' label\n",
        "    cluster_label_counts = data.groupby([cluster_col_name, actual_label_col_name]).size().unstack(fill_value=0)\n",
        "\n",
        "    cluster_stats = pd.DataFrame()\n",
        "    cluster_stats['cluster'] = cluster_label_counts.index\n",
        "    cluster_stats['total_sessions_in_cluster'] = cluster_label_counts.sum(axis=1)\n",
        "\n",
        "    # Iterate through unique actual_label_col_name values (0 and 1)\n",
        "    for label_status in data[actual_label_col_name].unique():\n",
        "        col_name_count = f'{actual_label_col_name}_{label_status}_count'\n",
        "        col_name_proportion = f'{actual_label_col_name}_{label_status}_proportion'\n",
        "\n",
        "        cluster_stats[col_name_count] = cluster_label_counts[label_status]\n",
        "        cluster_stats[col_name_proportion] = cluster_label_counts[label_status] / cluster_stats['total_sessions_in_cluster']\n",
        "\n",
        "    # Add more metrics as needed\n",
        "    return cluster_stats\n",
        "\n",
        "# Example usage with our cybersecurity dataset (without using 'attack_detected' as a feature for clustering)\n",
        "cluster_analysis_without_labels = analyze_clusters(dataset_data_without_labels_clustering, 'cluster_without_labels', 'attack_detected')\n",
        "print(\"Detailed Cluster Analysis (without 'attack_detected' as feature for clustering):\")\n",
        "cluster_analysis_without_labels"
      ],
      "metadata": {
        "id": "4weKSo81wZCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a copy of the raw data to work with, removing 'session_id' and 'attack_detected'\n",
        "df_cyber_without_labels = dataset_data.drop(columns=['session_id', 'attack_detected'])\n",
        "\n",
        "# Identify categorical columns for one-hot encoding\n",
        "columns_to_encode_without_labels = df_cyber_without_labels.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# One-hot encode the identified categorical features\n",
        "cyber_data_without_labels = pd.get_dummies(df_cyber_without_labels, columns=columns_to_encode_without_labels, drop_first=False)\n",
        "\n",
        "# Display the updated DataFrame with one-hot encoded features\n",
        "print(\"DataFrame with one-hot encoded features, without 'attack_detected':\")\n",
        "print(cyber_data_without_labels.head())"
      ],
      "metadata": {
        "id": "qSjCFM8PwZCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56680eff"
      },
      "source": [
        "### Interpreting the Visualization for Clusters (WITHOUT `attack_detected`)\n",
        "\n",
        "This scatter plot visualizes the cluster assignments (when `attack_detected` was *not* used as a feature for clustering) using `Network Packet Size` and `Session Duration` as the axes. This allows us to visually inspect the separation and characteristics of these three clusters.\n",
        "\n",
        "*   **Code Explanation (as a reminder)**:\n",
        "    *   Each point on the plot represents a cybersecurity session.\n",
        "    *   The color of each point indicates the cluster (`0`, `1`, or `2`) to which K-Means assigned that session.\n",
        "    *   The x-axis represents the `Network Packet Size`.\n",
        "    *   The y-axis represents the `Session Duration`.\n",
        "\n",
        "*   **Interpreting the Results**:\n",
        "    *   **Visual Overlap**: You will likely observe a significant degree of overlap between the different colored points. This means that sessions belonging to different clusters are not clearly separated in this 2D space defined by `network_packet_size` and `session_duration`.\n",
        "    *   **No Distinct Boundaries**: Unlike the scenario where `attack_detected` was explicitly used as a feature, it is difficult to identify clear boundaries or distinct regions for each cluster. The points from different clusters appear intermingled.\n",
        "    *   **Consistency with Numerical Analysis**: This visual observation supports the numerical analysis from `cluster_analysis_without_labels`. Since the numerical analysis showed that the clusters did not effectively separate attack from non-attack sessions, it follows that these clusters also don't show strong visual separation based on key features like `network_packet_size` and `session_duration`.\n",
        "\n",
        "This visualization further confirms that when K-Means operates in a purely unsupervised mode (without the `attack_detected` label), the clusters it forms, while grouping data points, do not necessarily correspond to a meaningful separation of attacks versus non-attacks based on these visible features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d97ecd99"
      },
      "source": [
        "### Interpreting the Visualization for Clusters (WITHOUT `attack_detected`)\n",
        "\n",
        "This scatter plot visualizes the cluster assignments (when `attack_detected` was *not* used as a feature for clustering) using `Network Packet Size` and `Session Duration` as the axes. This allows us to visually inspect the separation and characteristics of these `optimal_k = 6` clusters.\n",
        "\n",
        "* **Code Explanation (as a reminder)**:\n",
        "    * Each point on the plot represents a cybersecurity session.\n",
        "    * The color of each point indicates the cluster (0 through 5) to which K-Means assigned that session.\n",
        "    * The x-axis represents the `Network Packet Size`.\n",
        "    * The y-axis represents the `Session Duration`.\n",
        "\n",
        "* **Interpreting the Results**:\n",
        "    * **Visual Overlap**: You will likely observe a significant degree of overlap between the different colored points. This means that sessions belonging to different clusters are not clearly separated in this 2D space defined by `network_packet_size` and `session_duration`.\n",
        "    * **No Distinct Boundaries**: Unlike the scenario where `attack_detected` was explicitly used as a feature, it is difficult to identify clear boundaries or distinct regions for each cluster. The points from different clusters appear intermingled.\n",
        "    * **Consistency with Numerical Analysis**: This visual observation supports the numerical analysis from `cluster_analysis_without_labels`. Since the numerical analysis showed that the clusters did not effectively separate attack from non-attack sessions, it follows that these clusters also don't show strong visual separation based on key features like `network_packet_size` and `session_duration`.\n",
        "\n",
        "This visualization further confirms that when K-Means operates in a purely unsupervised mode (without the `attack_detected` label), the clusters it forms, while grouping data points, do not necessarily correspond to a meaningful separation of attacks versus non-attacks based on these visible features."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize cluster assignments\n",
        "plt.figure(figsize=(10, 6))\n",
        "for cluster_id in range(optimal_k):\n",
        "    cluster_data = dataset_data_without_labels_clustering[dataset_data_without_labels_clustering['cluster_without_labels'] == cluster_id]\n",
        "    plt.scatter(cluster_data['network_packet_size'], cluster_data['session_duration'], label=f'Cluster {cluster_id}')\n",
        "\n",
        "plt.xlabel('Network Packet Size')\n",
        "plt.ylabel('Session Duration')\n",
        "plt.title('Cluster Assignments (Network Packet Size vs. Session Duration, WITHOUT attack_detected as feature)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hIbrXbpGwZCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38a5ba09"
      },
      "source": [
        "---\n",
        "# 3. **CONCLUSION**\n",
        "\n",
        "## 3.1 Overall\n",
        "\n",
        "> This project explored the application of K-Means clustering to a cybersecurity intrusion detection dataset, comparing two main approaches: one where the `attack_detected` attribute was included as a feature for clustering, and another where it was explicitly excluded. In the first scenario, K-Means demonstrated a remarkable ability to separate the data into highly pure clusters, with one cluster almost exclusively containing non-attack sessions and another almost exclusively containing attack sessions. This indicates a strong inherent separability within the data when the 'attack detected' characteristic is leveraged during clustering. Conversely, when `attack_detected` was excluded, K-Means struggled to form clusters that meaningfully aligned with the presence or absence of an attack, resulting in mixed clusters with similar proportions of attack and non-attack sessions. This highlights the inherent challenge of purely unsupervised anomaly detection where the patterns of interest are not explicitly provided.\n",
        "\n",
        "## 3.2 Challenges and solutions\n",
        "\n",
        "> **Challenges Encountered:**\n",
        "> 1.  **Ambiguity in Unsupervised Clustering**: The primary challenge was the difficulty in getting K-Means to naturally 'discover' attack patterns when the `attack_detected` label was withheld. Without this direct signal, the algorithm found groupings based on other feature similarities, but these did not strongly correlate with actual attack events.\n",
        "> 2.  **Data Preprocessing for K-Means**: K-Means is sensitive to feature scaling and categorical data. Handling `object` (categorical) columns through one-hot encoding and ensuring numerical features were standardized were crucial steps.\n",
        "> 3.  **Optimal K Determination**: Identifying the optimal number of clusters (`k`) proved to be an interpretative task, relying on tools like the Elbow Method and Silhouette Score, which can sometimes be ambiguous.\n",
        ">\n",
        "> **Solutions Implemented:**\n",
        "> 1.  **Comprehensive Preprocessing**: Applied one-hot encoding to all categorical features (`protocol_type`, `encryption_used`, `browser_type`) and `StandardScaler` to all numerical features to ensure all attributes contributed fairly to the clustering process.\n",
        "> 2.  **Comparative Analysis**: Performed K-Means in two distinct modes (with and without `attack_detected` as a feature) to illustrate the impact of feature selection on clustering outcomes and to gauge inherent data separability.\n",
        "> 3.  **Hyperparameter Tuning**: Utilized the Elbow Method (inertia plot) and Silhouette Score plot to systematically test and identify a suitable `k` value for both clustering scenarios.\n",
        "\n",
        "## 3.3 Looking forward\n",
        "\n",
        "> Future work could build upon this foundation in several ways:\n",
        "> 1.  **Supervised Learning Transition**: Given the strong inherent separability observed, a natural next step would be to transition to supervised learning models (e.g., SVM, Random Forest, Neural Networks) for more accurate and direct attack detection.\n",
        "> 2.  **Advanced Feature Engineering**: Explore creating new, more complex features from the existing data that might enhance the distinctiveness of attack patterns, especially for the purely unsupervised approach.\n",
        "> 3.  **Alternative Unsupervised Algorithms**: Experiment with other unsupervised algorithms like DBSCAN (which can find clusters of varying shapes and handle noise) or hierarchical clustering to see if they yield better results in discovering attack patterns without the `attack_detected` label.\n",
        "> 4.  **Dimensionality Reduction**: Apply techniques like Principal Component Analysis (PCA) before clustering to reduce noise and potentially reveal clearer structures in a lower-dimensional space, which might improve the performance of K-Means when `attack_detected` is excluded.\n",
        "> 5.  **Investigation of Mixed Clusters**: Delve deeper into the characteristics of Cluster 0 (the mixed cluster from the 'with `attack_detected`' experiment) to understand why these sessions are ambiguous. This could uncover subtle attack vectors or normal traffic with unusual patterns requiring specialized handling.\n",
        "\n",
        "## 3.4 In hindsight\n",
        "\n",
        "> Reflecting on this project, the most significant insight is the critical role of feature selection in K-Means clustering, particularly in the context of unsupervised anomaly detection. While K-Means effectively grouped data when the target variable was indirectly provided (as a feature), its ability to 'discover' attacks without this explicit information was limited, suggesting that the raw features alone did not form naturally distinct attack/non-attack clusters. This underscores the difference between validating known patterns and genuinely discovering unknown ones. The importance of meticulous data preprocessing (one-hot encoding and scaling) for K-Means was also reaffirmed, as was the iterative nature of hyperparameter tuning. Understanding both the strengths and limitations of K-Means in different contexts is vital for its effective application in real-world cybersecurity scenarios.\n",
        "\n",
        "Thank you, Professor Joaquim :)"
      ]
    }
  ]
}